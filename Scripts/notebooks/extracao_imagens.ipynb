{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["\u003ca href=\"https://colab.research.google.com/github/5ury4pr454th/building-scene-classification/blob/main/Detect_and_Save_Test.ipynb\" target=\"_parent\"\u003e\u003cimg src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/\u003e\u003c/a\u003e"]},{"cell_type":"markdown","metadata":{"id":"Kn68499fPuEC"},"source":["## Importing Files"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39662,"status":"ok","timestamp":1730830843692,"user":{"displayName":"Rafael Pereira","userId":"17559057836265983982"},"user_tz":180},"id":"be1JMZ7V0VWx","outputId":"04e91147-713e-4fd4-9895-967d015aec10"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.17.0\n","The following GPU devices are available: /device:GPU:0\n","Mounted at /content/gdrive\n"]}],"source":["#@title\n","# For running inference on the TF-Hub module.\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","# for mounting drive and basic file navigation\n","import os\n","from google.colab import drive\n","\n","# for saving csv\n","import pandas as pd\n","\n","# For downloading the image.\n","import matplotlib.pyplot as plt\n","import tempfile\n","from six.moves.urllib.request import urlopen\n","from six import BytesIO\n","\n","# for additional dictionary tools\n","from collections import Counter\n","\n","# For drawing onto the image.\n","import numpy as np\n","from PIL import Image\n","from PIL import ImageColor\n","from PIL import ImageDraw\n","from PIL import ImageFont\n","from PIL import ImageOps\n","\n","# For measuring the inference time.\n","import time\n","\n","# Print Tensorflow version\n","print(tf.__version__)\n","\n","# Check available GPU devices.\n","print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())\n","\n","# mounting drive for using stored data\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"qA4mWNT5PzwY"},"source":["## Defining some functions for image preprocessing"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":286,"status":"ok","timestamp":1730830848480,"user":{"displayName":"Rafael Pereira","userId":"17559057836265983982"},"user_tz":180},"id":"6knqAigD-pPZ"},"outputs":[],"source":["#@title\n","def display_image(image):\n","    fig = plt.figure(figsize=(20, 15))\n","    plt.grid(False)\n","    plt.axis('off')\n","    plt.imshow(image)\n","    plt.show()\n","\n","\n","def download_and_resize_image(url, new_width=256, new_height=256,\n","                              display=False):\n","  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n","  response = urlopen(url)\n","  image_data = response.read()\n","  image_data = BytesIO(image_data)\n","  pil_image = Image.open(image_data)\n","  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.LANCZOs)\n","  pil_image_rgb = pil_image.convert(\"RGB\")\n","  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n","  print(\"Image downloaded to %s.\" % filename)\n","  if display:\n","    display_image(pil_image)\n","  return filename\n","\n","def draw_bounding_box_on_image(image, ymin, xmin, ymax, xmax, color, font, thickness=4, display_str_list=()):\n","    \"\"\"Adds a bounding box to an image.\"\"\"\n","    draw = ImageDraw.Draw(image)\n","    im_width, im_height = image.size\n","    (left, right, top, bottom) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n","    draw.line([(left, top), (left, bottom), (right, bottom), (right, top), (left, top)],\n","              width=thickness, fill=color)\n","\n","    display_str_heights = [font.getbbox(ds)[3] - font.getbbox(ds)[1] for ds in display_str_list]\n","    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n","\n","    if top \u003e total_display_str_height:\n","        text_bottom = top\n","    else:\n","        text_bottom = bottom + total_display_str_height\n","\n","    for display_str in display_str_list[::-1]:\n","        text_width, text_height = font.getbbox(display_str)[2], font.getbbox(display_str)[3] - font.getbbox(display_str)[1]\n","        margin = np.ceil(0.05 * text_height)\n","        draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n","                        (left + text_width, text_bottom)],\n","                       fill=color)\n","        draw.text((left + margin, text_bottom - text_height - margin),\n","                  display_str, fill=\"black\", font=font)\n","        text_bottom -= text_height + 2 * margin\n","\n","\n","def draw_boxes(image, boxes, class_names, scores, max_boxes=15, min_score=0.2):\n","    \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n","    colors = list(ImageColor.colormap.values())\n","\n","    try:\n","        font = ImageFont.truetype(\"/content/gdrive/MyDrive/Colab Notebooks/TCC/Scripts/indian-street-scenes/LiberationSansNarrow-Regular.ttf\", 25)\n","    except IOError:\n","        print(\"Font not found, using default font.\")\n","        font = ImageFont.load_default()\n","\n","    image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n","    for i in range(min(boxes.shape[0], max_boxes)):\n","        if scores[i] \u003e= min_score:\n","            ymin, xmin, ymax, xmax = tuple(boxes[i])\n","            display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"), int(100 * scores[i]))\n","            color = colors[hash(class_names[i]) % len(colors)]\n","            draw_bounding_box_on_image(image_pil, ymin, xmin, ymax, xmax, color, font, display_str_list=[display_str])\n","\n","    return np.array(image_pil)\n","\n","\n","def load_img(path):\n","  img = tf.io.read_file(path)\n","  img = tf.image.decode_jpeg(img, channels=3)\n","  return img\n","\n","def run_detector(detector, path, show=True):\n","    img = load_img(path)\n","\n","    converted_img = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n","    start_time = time.time()\n","    result = detector(converted_img)\n","    end_time = time.time()\n","\n","    result = {key: value.numpy() for key, value in result.items()}\n","\n","    print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n","    print(\"Inference time: \", end_time - start_time)\n","\n","    image_with_boxes = draw_boxes(img.numpy(), result[\"detection_boxes\"], result[\"detection_class_entities\"], result[\"detection_scores\"])\n","    if show:\n","        display_image(image_with_boxes)\n","\n","    return result[\"detection_boxes\"], result[\"detection_class_entities\"], result[\"detection_scores\"]\n","\n","\n","\n","def resize_and_save(image_path, final_path, width, height):\n","  pil_image = Image.open(image_path)\n","  pil_image = ImageOps.fit(pil_image, (width, height), Image.LANCZOS)\n","  pil_image_rgb = pil_image.convert(\"RGB\")\n","  pil_image_rgb.save(final_path, format=\"JPEG\", quality=90)\n","  pass\n","\n","def crop_bounding_box(img, bounding_box):\n","  ymin, xmin, ymax, xmax = tuple(bounding_box)\n","  return img.crop((xmin, ymin, xmax, ymax))\n","\n","def fit_and_save(img, final_path, width, height):\n","    cropped_img = ImageOps.fit(img, (width, height), Image.LANCZOS)\n","    cropped_img_rgb = cropped_img.convert(\"RGB\")\n","    cropped_img_rgb.save(final_path, format=\"JPEG\", quality=90)\n","    pass\n","\n","\n","def do_operations(filename):\n","\n","  # open image file\n","  img = Image.open(filename)\n","\n","  # rescale image\n","  img = ImageOps.fit(img, (resized_img_size, resized_img_size), Image.LANCZOS)\n","\n","  # convert to RGB if not\n","  img = img.convert(\"RGB\")\n","\n","  np_img = np.array(img)\n","\n","  return np_img"]},{"cell_type":"markdown","metadata":{"id":"ztQ6FRwOQCXy"},"source":["## Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"tJNsJrLv2yLs"},"source":["Processando Imagens Teste"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":21166,"status":"ok","timestamp":1730830914399,"user":{"displayName":"Rafael Pereira","userId":"17559057836265983982"},"user_tz":180},"id":"fKsJbWIWCrZG"},"outputs":[],"source":["#Modificando o tamanho das imagens\n","original_image_path = \"/content/gdrive/MyDrive/Colab Notebooks/TCC/Scripts/imagens_bd/test\"\n","\n","# Caminho onde as imagens redimensionadas serão salvas\n","resized_image_path = \"/content/gdrive/MyDrive/Colab Notebooks/TCC/Scripts/imagens_bd/test-resized\"\n","\n","\n","resized_street_image_dims_width = 700\n","resized_street_image_dims_height = 450\n","\n","\n","for root, dirs, files in os.walk(original_image_path):\n","    for file in files:\n","        file_path = os.path.join(root, file)\n","        relative_path = os.path.relpath(root, original_image_path)\n","        save_dir = os.path.join(resized_image_path, relative_path)\n","        os.makedirs(save_dir, exist_ok=True)\n","        save_path = os.path.join(save_dir, file)\n","        resize_and_save(file_path, save_path, resized_street_image_dims_width, resized_street_image_dims_height)"]},{"cell_type":"markdown","metadata":{"id":"wqzcGZWP20_I"},"source":["Processando Imagens Treinamento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Alj01p2f2pC3"},"outputs":[],"source":["#Modificando o tamanho das imagens\n","original_image_path = \"/content/gdrive/MyDrive/Colab Notebooks/TCC/Scripts/imagens_bd/train\"\n","\n","# Caminho onde as imagens redimensionadas serão salvas\n","resized_image_path = \"/content/gdrive/MyDrive/Colab Notebooks/TCC/Scripts/imagens_bd/train-resized\"\n","\n","\n","resized_street_image_dims_width = 700\n","resized_street_image_dims_height = 450\n","\n","\n","for root, dirs, files in os.walk(original_image_path):\n","    for file in files:\n","        file_path = os.path.join(root, file)\n","        relative_path = os.path.relpath(root, original_image_path)\n","        save_dir = os.path.join(resized_image_path, relative_path)\n","        os.makedirs(save_dir, exist_ok=True)\n","        save_path = os.path.join(save_dir, file)\n","        resize_and_save(file_path, save_path, resized_street_image_dims_width, resized_street_image_dims_height)"]},{"cell_type":"markdown","metadata":{"id":"TdYu3E_7lcXX"},"source":["Classes para funcionar de acordo com o dataset de teste"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":275,"status":"ok","timestamp":1730830929938,"user":{"displayName":"Rafael Pereira","userId":"17559057836265983982"},"user_tz":180},"id":"HwQ2Hr_TD92m"},"outputs":[],"source":["#classes para funcionar de acordo com o dataset de teste\n","classes = [\"residential\", \"commercial\",\"others\",\"industrial\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OdnQ5dtxrG0p"},"outputs":[],"source":["#classes para funcionar de acordo com o dataset de treinamento\n","classes = [\"residential\", \"mixed\", \"commercial\",\"others\",\"industrial\"]"]},{"cell_type":"markdown","metadata":{"id":"GS0_LDMoQGPz"},"source":["## Detection using pretrained model"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":77296,"status":"ok","timestamp":1730831008694,"user":{"displayName":"Rafael Pereira","userId":"17559057836265983982"},"user_tz":180},"id":"DjBLUSou3UxO"},"outputs":[],"source":["module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n","detector = hub.load(module_handle).signatures['default']"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":295,"status":"ok","timestamp":1730831351662,"user":{"displayName":"Rafael Pereira","userId":"17559057836265983982"},"user_tz":180},"id":"HlSBxEVZZwES"},"outputs":[],"source":["resized_img_size = 500\n","cropped_dims = 800\n","frequency_dict = dict()\n","predicted_dict = {}\n","resized_street_image_dims = 800\n","instances_folder = \"/content/gdrive/MyDrive/Colab Notebooks/TCC/Scripts/imagens_bd/results_test\"\n","\n","resized_images_path = '/content/gdrive/MyDrive/Colab Notebooks/TCC/Scripts/imagens_bd/test-resized'"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":289,"status":"ok","timestamp":1730831355994,"user":{"displayName":"Rafael Pereira","userId":"17559057836265983982"},"user_tz":180},"id":"94DkVsy8VAk2"},"outputs":[],"source":["expansions = [resized_street_image_dims_height, resized_street_image_dims_width, resized_street_image_dims_height, resized_street_image_dims_width]"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1rcd7OXJmp7yp-bUrt0Os6EvCgUCvEgjp"},"executionInfo":{"elapsed":35533,"status":"ok","timestamp":1730831489057,"user":{"displayName":"Rafael Pereira","userId":"17559057836265983982"},"user_tz":180},"id":"mP03kuRZQocY","outputId":"6f2993d6-ecd6-47ca-b047-c074c0569267"},"outputs":[],"source":["for bclass in classes:\n","\n","  for i in os.listdir(resized_images_path +'/'+ bclass + '/'):\n","\n","    predicted_dict[bclass +'/' + i] = []\n","    bounding_objects = []\n","\n","    # for each image, run the detector and get the bounding boxes and corresponding\n","    img = Image.open(resized_images_path + '/'+ bclass + '/' + i)\n","    bounding_boxes, raw_bounding_classes, class_scores = run_detector(detector, resized_images_path + '/' + bclass + '/' + i, show=True)\n","\n","    # for each of the objects detected, check if house, skyscraper or building, crop according to priority, and save them to the cropped_folder\n","    for index, i3 in enumerate(raw_bounding_classes):\n","      i1 = str(i3)[2:-1].lower()\n","      if i1 in ['house', 'building', 'skyscraper', 'tower'] and class_scores[index] \u003e 0.3:\n","        final_path = instances_folder + \"/\" + bclass + '/' + str(index) + '_' + i\n","        expanded_boxes = np.asarray(tuple(expansions)) * np.asarray(bounding_boxes[index])\n","        house_bound = crop_bounding_box(img, expanded_boxes)\n","        house_bound = fit_and_save(house_bound, final_path, 500, 700)\n","\n","    for objects in range(len(raw_bounding_classes)):\n","      if class_scores[objects] \u003e= 0.4:\n","        bounding_objects.append(str(raw_bounding_classes[objects])[2:-1].lower())\n","\n","    # record the number of objects detected\n","    frequency_dict[bclass +'/' + i] = Counter(bounding_objects)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}