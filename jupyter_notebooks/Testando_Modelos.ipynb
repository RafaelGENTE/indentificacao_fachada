{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\tcc_ide\\venv\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: xgboost in c:\\tcc_ide\\venv\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in c:\\tcc_ide\\venv\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: matplotlib in c:\\tcc_ide\\venv\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\tcc_ide\\venv\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: opencv-python in c:\\tcc_ide\\venv\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: pillow in c:\\tcc_ide\\venv\\lib\\site-packages (11.0.0)\n",
      "Requirement already satisfied: seaborn in c:\\tcc_ide\\venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas in c:\\tcc_ide\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: setuptools in c:\\tcc_ide\\venv\\lib\\site-packages (75.6.0)\n",
      "Requirement already satisfied: openpyxl in c:\\tcc_ide\\venv\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: scipy in c:\\tcc_ide\\venv\\lib\\site-packages (from xgboost) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\tcc_ide\\venv\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\tcc_ide\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\tcc_ide\\venv\\lib\\site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\tcc_ide\\venv\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\tcc_ide\\venv\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\tcc_ide\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\tcc_ide\\venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\tcc_ide\\venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\tcc_ide\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\tcc_ide\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\tcc_ide\\venv\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\tcc_ide\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\tcc_ide\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\tcc_ide\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\tcc_ide\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\tcc_ide\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\tcc_ide\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\tcc_ide\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\tcc_ide\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\tcc_ide\\venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\tcc_ide\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\tcc_ide\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\tcc_ide\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\tcc_ide\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow xgboost numpy matplotlib scikit-learn opencv-python pillow seaborn pandas setuptools openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vz2u_wL0v9Nr",
    "outputId": "04f3f6af-0603-4ef0-c76d-83abded3a8e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy: <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x0000023196BE48C0>\n"
     ]
    }
   ],
   "source": [
    "# some basic libraries\n",
    "import xgboost\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# importing for basic image operations\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# data structures\n",
    "from collections import OrderedDict\n",
    "\n",
    "# importing pretrained models\n",
    "from tensorflow.keras.applications import efficientnet\n",
    "\n",
    "# for splitting data\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# prerequisites for training models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# for selecting better metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# initialize TPU\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)  # Atualização aqui\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(f\"Strategy: {strategy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qHPmaNQS1eCW"
   },
   "outputs": [],
   "source": [
    "# variables to change\n",
    "\n",
    "TRAIN_IMG_DIR_PATH = \"../dados/results_train\"\n",
    "#TEST_IMG_DIR_PATH = \"../dados/results_test\" \n",
    "TEST_IMG_DIR_PATH = \"../dados/results_train\"\n",
    "TRAIN_SC_DIR_PATH = \"../dados/train-resized\"\n",
    "TEST_SC_DIR_PATH = \"../dados/test-resized\"\n",
    "model_path = \"../modelo\"\n",
    "#classes = [\"residential\", \"mixed\", \"commercial\",\"others\",\"industrial\"]\n",
    "classes = [\"residential\", \"commercial\",\"others\",\"industrial\"]\n",
    "\n",
    "INPUT_IMG_WIDTH = 250\n",
    "INPUT_IMG_HEIGHT = 350\n",
    "VERTICAL = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando modelos 100 epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: filepath=../modelo/modelo_att(100e).keras. Please ensure the file is an accessible `.keras` zip file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_eff_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodelo_att(100e).keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\tcc_ide\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:200\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[0;32m    197\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m     )\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmight have a different name).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: File not found: filepath=../modelo/modelo_att(100e).keras. Please ensure the file is an accessible `.keras` zip file."
     ]
    }
   ],
   "source": [
    "new_eff_model = tf.keras.models.load_model(model_path + '/' + 'modelo_att(100e).keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Wa37moztmVPz"
   },
   "outputs": [],
   "source": [
    "new_eff_model.load_weights(model_path + '/' + 'modelo_att.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZd52xTW4fk1",
    "outputId": "5d9c5d94-ca9c-468a-a1db-a7a261f563c3"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "target_class = \"residential\"\n",
    "residential_prediction_mapping = OrderedDict()\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "  for file_name in os.listdir(TEST_IMG_DIR_PATH + '/' + target_class):\n",
    "\n",
    "    img = Image.open(TEST_IMG_DIR_PATH + '/' + target_class + '/'+ file_name)\n",
    "    building_image = np.array(ImageOps.fit(img,(250, 350), Image.LANCZOS))\n",
    "    building_image = np.expand_dims(building_image, axis = 0)\n",
    "    residential_prediction_mapping[target_class + '/'+ file_name] = new_eff_model.predict(building_image)\n",
    "\n",
    "target_class = \"commercial\"\n",
    "commercial_prediction_mapping = OrderedDict()\n",
    "with strategy.scope():\n",
    "\n",
    "  for file_name in os.listdir(TEST_IMG_DIR_PATH + '/' + target_class):\n",
    "    img = Image.open(TEST_IMG_DIR_PATH + '/' + target_class + '/'+ file_name)\n",
    "    building_image = np.array(ImageOps.fit(img,(250, 350), Image.LANCZOS))\n",
    "    building_image = np.expand_dims(building_image, axis = 0)\n",
    "    commercial_prediction_mapping[target_class + '/'+ file_name] = new_eff_model.predict(building_image)\n",
    "\n",
    "target_class = \"industrial\"\n",
    "industrial_prediction_mapping = OrderedDict()\n",
    "with strategy.scope():\n",
    "\n",
    "  for file_name in os.listdir(TEST_IMG_DIR_PATH + '/' + target_class):\n",
    "    img = Image.open(TEST_IMG_DIR_PATH + '/' + target_class + '/'+ file_name)\n",
    "    building_image = np.array(ImageOps.fit(img,(250, 350), Image.LANCZOS))\n",
    "    building_image = np.expand_dims(building_image, axis = 0)\n",
    "    industrial_prediction_mapping[target_class + '/'+ file_name] = new_eff_model.predict(building_image)\n",
    "\n",
    "target_class = \"others\"\n",
    "others_prediction_mapping = OrderedDict()\n",
    "with strategy.scope():\n",
    "\n",
    "  for file_name in os.listdir(TEST_IMG_DIR_PATH + '/' + target_class):\n",
    "\n",
    "    img = Image.open(TEST_IMG_DIR_PATH + '/' + target_class + '/'+ file_name)\n",
    "    building_image = np.array(ImageOps.fit(img,(250, 350), Image.LANCZOS))\n",
    "    building_image = np.expand_dims(building_image, axis = 0)\n",
    "    others_prediction_mapping[file_name] = new_eff_model.predict(building_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tnGB8jlN59nt"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "others_predictions = OrderedDict()\n",
    "\n",
    "for file_name in others_prediction_mapping.keys():\n",
    "  # others_predictions[file_name] = np.argmax(others_prediction_mapping[file_name], axis = 1)[0]\n",
    "  others_predictions[file_name] = others_prediction_mapping[file_name]\n",
    "\n",
    "others_scene_predictions = OrderedDict()\n",
    "for file_name in others_predictions.keys():\n",
    "  scene_file_name = '_'.join(os.path.splitext(file_name)[0].split('_')[-3:]) + os.path.splitext(file_name)[1]\n",
    "  if scene_file_name not in others_scene_predictions.keys():\n",
    "    others_scene_predictions[scene_file_name] = [others_predictions[file_name]]\n",
    "  else:\n",
    "    others_scene_predictions[scene_file_name].append(others_predictions[file_name])\n",
    "\n",
    "residential_predictions = OrderedDict()\n",
    "for file_name in residential_prediction_mapping.keys():\n",
    "  # residential_predictions[file_name] = np.argmax(residential_prediction_mapping[file_name], axis = 1)[0]\n",
    "\n",
    "  residential_predictions[file_name] = residential_prediction_mapping[file_name]\n",
    "\n",
    "residential_scene_predictions = OrderedDict()\n",
    "for file_name in residential_predictions.keys():\n",
    "  scene_file_name = '_'.join(os.path.splitext(file_name)[0].split('_')[-3:]) + os.path.splitext(file_name)[1]\n",
    "  if scene_file_name not in residential_scene_predictions.keys():\n",
    "    residential_scene_predictions[scene_file_name] = [residential_predictions[file_name]]\n",
    "  else:\n",
    "    residential_scene_predictions[scene_file_name].append(residential_predictions[file_name])\n",
    "\n",
    "commercial_predictions = OrderedDict()\n",
    "for file_name in commercial_prediction_mapping.keys():\n",
    "  # commercial_predictions[file_name] = np.argmax(commercial_prediction_mapping[file_name], axis = 1)[0]\n",
    "\n",
    "  commercial_predictions[file_name] = commercial_prediction_mapping[file_name]\n",
    "commercial_scene_predictions = OrderedDict()\n",
    "for file_name in commercial_predictions.keys():\n",
    "  scene_file_name = '_'.join(os.path.splitext(file_name)[0].split('_')[-3:]) + os.path.splitext(file_name)[1]\n",
    "  if scene_file_name not in commercial_scene_predictions.keys():\n",
    "    commercial_scene_predictions[scene_file_name] = [commercial_predictions[file_name]]\n",
    "  else:\n",
    "    commercial_scene_predictions[scene_file_name].append(commercial_predictions[file_name])\n",
    "\n",
    "industrial_predictions = OrderedDict()\n",
    "for file_name in industrial_prediction_mapping.keys():\n",
    "  # industrial_predictions[file_name] = np.argmax(industrial_prediction_mapping[file_name], axis = 1)[0]\n",
    "\n",
    "  industrial_predictions[file_name] = industrial_prediction_mapping[file_name]\n",
    "industrial_scene_predictions = OrderedDict()\n",
    "for file_name in industrial_predictions.keys():\n",
    "  scene_file_name = '_'.join(os.path.splitext(file_name)[0].split('_')[-3:]) + os.path.splitext(file_name)[1]\n",
    "  if scene_file_name not in industrial_scene_predictions.keys():\n",
    "    industrial_scene_predictions[scene_file_name] = [industrial_predictions[file_name]]\n",
    "  else:\n",
    "    industrial_scene_predictions[scene_file_name].append(industrial_predictions[file_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbqYZtd8VxeZ"
   },
   "source": [
    " Visualizar Imagens e Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TVofeHZWVv8a",
    "outputId": "eec9e7ab-b1be-4fd4-ad47-a1c9b3646824"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Function to plot a sample of the images and their predictions\n",
    "def plot_sample_images(prediction_mapping, target_class, num_samples=10):\n",
    "    sample_predictions = list(prediction_mapping.items())[:num_samples]\n",
    "    for file_path, prediction in sample_predictions:\n",
    "        # Check if the path does not start with any of the known prefixes\n",
    "        print(file_path)\n",
    "        if not file_path.startswith(('commercial', 'residential', 'industrial')):\n",
    "            file_path = 'others/' + file_path\n",
    "\n",
    "        img = Image.open(TEST_IMG_DIR_PATH + '/' + file_path)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Prediction: {np.argmax(prediction)}\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Plot sample images and their predictions for each class\n",
    "print(\"Residential Images and Predictions:\")\n",
    "plot_sample_images(residential_prediction_mapping, \"residential\")\n",
    "\n",
    "print(\"Commercial Images and Predictions:\")\n",
    "plot_sample_images(commercial_prediction_mapping, \"commercial\")\n",
    "\n",
    "print(\"Industrial Images and Predictions:\")\n",
    "plot_sample_images(industrial_prediction_mapping, \"industrial\")\n",
    "\n",
    "print(\"Other Images and Predictions:\")\n",
    "plot_sample_images(others_prediction_mapping, \"others\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exibir as imagens com as porcentagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Função para calcular as porcentagens das predições e exibir as imagens\n",
    "def plot_sample_images_with_percentages(prediction_mapping, target_class, num_samples=10):\n",
    "    sample_predictions = list(prediction_mapping.items())[:num_samples]\n",
    "\n",
    "    for file_path, prediction in sample_predictions:\n",
    "        # Ajustar o caminho do arquivo para a categoria \"others\", se necessário\n",
    "        if not file_path.startswith(('commercial', 'residential', 'industrial')):\n",
    "            file_path = 'others/' + file_path\n",
    "\n",
    "        # Carregar a imagem\n",
    "        img = Image.open(TEST_IMG_DIR_PATH + '/' + file_path)\n",
    "\n",
    "        # Calcular as porcentagens para cada classe\n",
    "        percentages = {cls: round(prob * 100, 2) for cls, prob in zip(classes, prediction[0])}\n",
    "\n",
    "        # Criar um título com as porcentagens das predições\n",
    "        title = \"\\n\".join([f\"{cls}: {percent}%\" for cls, percent in percentages.items()])\n",
    "\n",
    "        # Exibir a imagem com o título\n",
    "        plt.figure(figsize=(5, 7))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(title, fontsize=10)\n",
    "        plt.show()\n",
    "\n",
    "# Plotando as imagens e suas predições para cada classe\n",
    "print(\"Residential Images and Predictions:\")\n",
    "plot_sample_images_with_percentages(residential_prediction_mapping, \"residential\")\n",
    "\n",
    "print(\"Commercial Images and Predictions:\")\n",
    "plot_sample_images_with_percentages(commercial_prediction_mapping, \"commercial\")\n",
    "\n",
    "print(\"Industrial Images and Predictions:\")\n",
    "plot_sample_images_with_percentages(industrial_prediction_mapping, \"industrial\")\n",
    "\n",
    "print(\"Other Images and Predictions:\")\n",
    "plot_sample_images_with_percentages(others_prediction_mapping, \"others\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Função para calcular as porcentagens das predições e salvar as imagens\n",
    "def save_sample_images_with_percentages(prediction_mapping, target_class, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Garante que o diretório de saída exista\n",
    "\n",
    "    for file_path, prediction in prediction_mapping.items():\n",
    "        # Ajustar o caminho do arquivo para a categoria \"others\", se necessário\n",
    "        if not file_path.startswith(('commercial', 'residential', 'industrial')):\n",
    "            file_path = 'others/' + file_path\n",
    "\n",
    "        # Carregar a imagem\n",
    "        img = Image.open(TEST_IMG_DIR_PATH + '/' + file_path)\n",
    "\n",
    "        # Calcular as porcentagens para cada classe\n",
    "        percentages = {cls: round(prob * 100, 2) for cls, prob in zip(classes, prediction[0])}\n",
    "\n",
    "        # Criar um título com as porcentagens das predições\n",
    "        title = \"\\n\".join([f\"{cls}: {percent}%\" for cls, percent in percentages.items()])\n",
    "\n",
    "        # Exibir a imagem com o título e salvar como arquivo JPEG\n",
    "        plt.figure(figsize=(5, 7))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(title, fontsize=10)\n",
    "\n",
    "        # Salvar a imagem na pasta de saída\n",
    "        output_path = os.path.join(output_dir, file_path.replace(\"/\", \"_\").replace(\"\\\\\", \"_\") + \".jpeg\")\n",
    "        plt.savefig(output_path, format='jpeg', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# Diretório de saída\n",
    "output_base_dir = \"output_images_2\"\n",
    "\n",
    "# Salvando as imagens para cada classe\n",
    "save_sample_images_with_percentages(residential_prediction_mapping, \"residential\", os.path.join(output_base_dir, \"residential\"))\n",
    "save_sample_images_with_percentages(commercial_prediction_mapping, \"commercial\", os.path.join(output_base_dir, \"commercial\"))\n",
    "save_sample_images_with_percentages(industrial_prediction_mapping, \"industrial\", os.path.join(output_base_dir, \"industrial\"))\n",
    "save_sample_images_with_percentages(others_prediction_mapping, \"others\", os.path.join(output_base_dir, \"others\"))\n",
    "\n",
    "print(f\"Imagens salvas na pasta '{output_base_dir}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportar as tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_predictions_with_percentages(image_dir, target_class, model, classes):\n",
    "    prediction_mapping = OrderedDict()\n",
    "\n",
    "    for file_name in os.listdir(image_dir + '/' + target_class):\n",
    "        img = Image.open(image_dir + '/' + target_class + '/' + file_name)\n",
    "        building_image = np.array(ImageOps.fit(img, (INPUT_IMG_WIDTH, INPUT_IMG_HEIGHT), Image.LANCZOS))\n",
    "        building_image = np.expand_dims(building_image, axis=0)\n",
    "        prediction = model.predict(building_image)[0]  # Obter o vetor de probabilidades\n",
    "        percentages = {cls: f\"{round(prob * 100, 2)}%\" for cls, prob in zip(classes, prediction)}\n",
    "        prediction_mapping[file_name] = percentages\n",
    "\n",
    "    return prediction_mapping\n",
    "\n",
    "# Gera predições para todas as classes\n",
    "all_predictions = {}\n",
    "for target_class in classes:\n",
    "    predictions = get_predictions_with_percentages(TEST_IMG_DIR_PATH, target_class, new_eff_model, classes)\n",
    "    all_predictions[target_class] = predictions\n",
    "\n",
    "# Criar uma tabela visual\n",
    "def create_prediction_table(predictions_dict):\n",
    "    all_data = []\n",
    "    for target_class, predictions in predictions_dict.items():\n",
    "        for file_name, percentages in predictions.items():\n",
    "            row = {\"Image\": file_name, \"True Class\": target_class, **percentages}\n",
    "            all_data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "# Cria tabela consolidada\n",
    "prediction_table = create_prediction_table(all_predictions)\n",
    "\n",
    "# Salva a tabela em um arquivo Excel\n",
    "output_path = \"prediction_percentages_table.xlsx\"\n",
    "prediction_table.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"A tabela foi salva em: {output_path}\")\n",
    "\n",
    "# Exibe a tabela diretamente no console\n",
    "print(prediction_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportar as tabelas com as imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions with images saved to: predictions_with_images.xlsx\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "from openpyxl.drawing.image import Image as OpenPyxlImage\n",
    "import os\n",
    "\n",
    "def save_predictions_with_images_to_excel(predictions_dict, image_dir, output_path, classes):\n",
    "    # Cria uma pasta temporária para salvar as imagens\n",
    "    temp_image_dir = \"temp_images\"\n",
    "    os.makedirs(temp_image_dir, exist_ok=True)\n",
    "\n",
    "    # Cria uma nova planilha Excel\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Predictions\"\n",
    "\n",
    "    # Cabeçalhos\n",
    "    headers = [\"Image\", \"True Class\", \"Image Path\"] + classes\n",
    "    ws.append(headers)\n",
    "\n",
    "    # Adiciona as predições e imagens à planilha\n",
    "    row_index = 2\n",
    "    for target_class, predictions in predictions_dict.items():\n",
    "        for file_name, percentages in predictions.items():\n",
    "            # Salvar a imagem temporariamente\n",
    "            img_path = os.path.join(image_dir, target_class, file_name)\n",
    "            temp_img_path = os.path.join(temp_image_dir, file_name)\n",
    "            img = Image.open(img_path)\n",
    "            img.save(temp_img_path)\n",
    "\n",
    "            # Adiciona as informações à planilha\n",
    "            row = [file_name, target_class, temp_img_path] + [percentages[cls] for cls in classes]\n",
    "            ws.append(row)\n",
    "\n",
    "            # Insere a imagem na célula correspondente\n",
    "            img_openpyxl = OpenPyxlImage(temp_img_path)\n",
    "            ws.add_image(img_openpyxl, f\"C{row_index}\")\n",
    "\n",
    "            row_index += 1\n",
    "\n",
    "    # Salva a planilha\n",
    "    wb.save(output_path)\n",
    "\n",
    "    # Remove as imagens temporárias\n",
    "    for temp_file in os.listdir(temp_image_dir):\n",
    "        os.remove(os.path.join(temp_image_dir, temp_file))\n",
    "    os.rmdir(temp_image_dir)\n",
    "\n",
    "    print(f\"Predictions with images saved to: {output_path}\")\n",
    "\n",
    "# Gera a tabela com as predições e imagens\n",
    "output_excel_path = \"predictions_with_images.xlsx\"\n",
    "save_predictions_with_images_to_excel(all_predictions, TEST_IMG_DIR_PATH, output_excel_path, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# Função para calcular métricas\n",
    "def calculate_metrics(y_true, y_pred, y_prob, class_names):\n",
    "    metrics = {}\n",
    "\n",
    "    # Acurácia\n",
    "    metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Precisão, Recall, F1-Score\n",
    "    metrics['precision'] = precision_score(y_true, y_pred, average='weighted')\n",
    "    metrics['recall'] = recall_score(y_true, y_pred, average='weighted')\n",
    "    metrics['f1_score'] = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    # Matriz de Confusão\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    metrics['confusion_matrix'] = cm\n",
    "\n",
    "    # Relatório de Classificação\n",
    "    metrics['classification_report'] = classification_report(y_true, y_pred, target_names=class_names)\n",
    "\n",
    "    # AUC-ROC (se y_prob estiver disponível)\n",
    "    if y_prob is not None:\n",
    "        metrics['roc_auc'] = roc_auc_score(y_true, y_prob, multi_class='ovr', average='weighted')\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Preparando os dados para cálculo\n",
    "def prepare_data_for_metrics(prediction_mapping, target_class_index):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_prob = []\n",
    "\n",
    "    for file_name, predictions in prediction_mapping.items():\n",
    "        y_true.append(target_class_index)  # Classe verdadeira\n",
    "        y_pred.append(np.argmax(predictions))  # Classe predita\n",
    "        y_prob.append(predictions[0])  # Vetor de probabilidades\n",
    "\n",
    "    return y_true, y_pred, y_prob\n",
    "\n",
    "# Consolida os dados de todas as classes\n",
    "y_true_all, y_pred_all, y_prob_all = [], [], []\n",
    "\n",
    "for idx, target_class in enumerate(classes):\n",
    "    y_true, y_pred, y_prob = prepare_data_for_metrics(\n",
    "        locals()[f\"{target_class}_prediction_mapping\"], idx\n",
    "    )\n",
    "    y_true_all.extend(y_true)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    y_prob_all.extend(y_prob)\n",
    "\n",
    "# Calcula as métricas\n",
    "metrics = calculate_metrics(y_true_all, y_pred_all, y_prob_all, classes)\n",
    "\n",
    "# Exibindo as métricas\n",
    "print(\"Acurácia:\", metrics['accuracy'])\n",
    "print(\"\\nPrecisão:\", metrics['precision'])\n",
    "print(\"\\nRecall:\", metrics['recall'])\n",
    "print(\"\\nF1-Score:\", metrics['f1_score'])\n",
    "print(\"\\nMatriz de Confusão:\\n\", metrics['confusion_matrix'])\n",
    "print(\"\\nRelatório de Classificação:\\n\", metrics['classification_report'])\n",
    "\n",
    "if 'roc_auc' in metrics:\n",
    "    print(\"\\nAUC-ROC:\", metrics['roc_auc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configurar o diretório de logs para o TensorBoard\n",
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "# Função para logar métricas no TensorBoard\n",
    "def log_metrics_to_tensorboard(metrics, y_true, y_pred, class_names, step=0):\n",
    "    with summary_writer.as_default():\n",
    "        # Logar métricas gerais\n",
    "        tf.summary.scalar(\"Accuracy\", metrics['accuracy'], step=step)\n",
    "        tf.summary.scalar(\"Precision\", metrics['precision'], step=step)\n",
    "        tf.summary.scalar(\"Recall\", metrics['recall'], step=step)\n",
    "        tf.summary.scalar(\"F1 Score\", metrics['f1_score'], step=step)\n",
    "        \n",
    "        if 'roc_auc' in metrics:\n",
    "            tf.summary.scalar(\"AUC-ROC\", metrics['roc_auc'], step=step)\n",
    "        \n",
    "        # Matriz de Confusão como imagem\n",
    "        cm = metrics['confusion_matrix']\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        \n",
    "        # Salvar a matriz de confusão como imagem no TensorBoard\n",
    "        plt.savefig(\"confusion_matrix.png\")\n",
    "        plt.close()\n",
    "        cm_image = tf.io.read_file(\"confusion_matrix.png\")\n",
    "        cm_image = tf.image.decode_png(cm_image)\n",
    "        tf.summary.image(\"Confusion Matrix\", tf.expand_dims(cm_image, axis=0), step=step)\n",
    "\n",
    "# Preparando os dados para cálculo\n",
    "def prepare_data_for_metrics(prediction_mapping, target_class_index):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_prob = []\n",
    "\n",
    "    for file_name, predictions in prediction_mapping.items():\n",
    "        y_true.append(target_class_index)  # Classe verdadeira\n",
    "        y_pred.append(np.argmax(predictions))  # Classe predita\n",
    "        y_prob.append(predictions[0])  # Vetor de probabilidades\n",
    "\n",
    "    return y_true, y_pred, y_prob\n",
    "\n",
    "# Consolida os dados de todas as classes\n",
    "y_true_all, y_pred_all, y_prob_all = [], [], []\n",
    "\n",
    "for idx, target_class in enumerate(classes):\n",
    "    y_true, y_pred, y_prob = prepare_data_for_metrics(\n",
    "        locals()[f\"{target_class}_prediction_mapping\"], idx\n",
    "    )\n",
    "    y_true_all.extend(y_true)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    y_prob_all.extend(y_prob)\n",
    "\n",
    "# Calcula as métricas\n",
    "metrics = calculate_metrics(y_true_all, y_pred_all, y_prob_all, classes)\n",
    "\n",
    "# Exibindo as métricas no console\n",
    "print(\"Acurácia:\", metrics['accuracy'])\n",
    "print(\"\\nPrecisão:\", metrics['precision'])\n",
    "print(\"\\nRecall:\", metrics['recall'])\n",
    "print(\"\\nF1-Score:\", metrics['f1_score'])\n",
    "print(\"\\nMatriz de Confusão:\\n\", metrics['confusion_matrix'])\n",
    "print(\"\\nRelatório de Classificação:\\n\", metrics['classification_report'])\n",
    "\n",
    "if 'roc_auc' in metrics:\n",
    "    print(\"\\nAUC-ROC:\", metrics['roc_auc'])\n",
    "\n",
    "# Logar métricas no TensorBoard\n",
    "log_metrics_to_tensorboard(metrics, y_true_all, y_pred_all, classes)\n",
    "\n",
    "# Iniciar o TensorBoard (apenas no notebook, opcional)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score\n",
    ")\n",
    "\n",
    "# Funções auxiliares\n",
    "def calculate_metrics(y_true, y_pred, y_prob, class_names):\n",
    "    metrics = {}\n",
    "\n",
    "    # Acurácia\n",
    "    metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Precisão, Recall, F1-Score\n",
    "    metrics['precision'] = precision_score(y_true, y_pred, average='weighted')\n",
    "    metrics['recall'] = recall_score(y_true, y_pred, average='weighted')\n",
    "    metrics['f1_score'] = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    # Matriz de Confusão\n",
    "    metrics['confusion_matrix'] = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Relatório de Classificação\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "    metrics['classification_report'] = report\n",
    "\n",
    "    # AUC-ROC (se y_prob estiver disponível)\n",
    "    if y_prob is not None:\n",
    "        metrics['roc_auc'] = roc_auc_score(y_true, y_prob, multi_class='ovr', average='weighted')\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def prepare_data_for_metrics(prediction_mapping, target_class_index):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_prob = []\n",
    "\n",
    "    for file_name, predictions in prediction_mapping.items():\n",
    "        y_true.append(target_class_index)  # Classe verdadeira\n",
    "        y_pred.append(np.argmax(predictions))  # Classe predita\n",
    "        y_prob.append(predictions[0])  # Vetor de probabilidades\n",
    "\n",
    "    return y_true, y_pred, y_prob\n",
    "\n",
    "def save_metrics_to_excel(metrics, output_path, class_names):\n",
    "    with pd.ExcelWriter(output_path) as writer:\n",
    "        # Salva métricas gerais\n",
    "        general_metrics = {\n",
    "            \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"AUC-ROC\"],\n",
    "            \"Value\": [\n",
    "                metrics.get('accuracy', 'N/A'),\n",
    "                metrics.get('precision', 'N/A'),\n",
    "                metrics.get('recall', 'N/A'),\n",
    "                metrics.get('f1_score', 'N/A'),\n",
    "                metrics.get('roc_auc', 'N/A'),\n",
    "            ]\n",
    "        }\n",
    "        pd.DataFrame(general_metrics).to_excel(writer, sheet_name=\"General Metrics\", index=False)\n",
    "\n",
    "        # Salva matriz de confusão\n",
    "        cm_df = pd.DataFrame(metrics['confusion_matrix'], index=class_names, columns=class_names)\n",
    "        cm_df.to_excel(writer, sheet_name=\"Confusion Matrix\")\n",
    "\n",
    "        # Salva relatório de classificação\n",
    "        report_dict = metrics['classification_report']\n",
    "        report_df = pd.DataFrame(report_dict).transpose()\n",
    "        report_df.to_excel(writer, sheet_name=\"Classification Report\", index=True)\n",
    "\n",
    "# Variáveis do modelo e predições (preencher com seus dados)\n",
    "classes = [\"residential\", \"commercial\", \"others\", \"industrial\"]\n",
    "\n",
    "# Exemplo para carregar predições (substitua pelos seus dados reais)\n",
    "# y_true_all, y_pred_all, y_prob_all devem ser gerados a partir das predições\n",
    "y_true_all, y_pred_all, y_prob_all = [], [], []\n",
    "\n",
    "for idx, target_class in enumerate(classes):\n",
    "    y_true, y_pred, y_prob = prepare_data_for_metrics(\n",
    "        locals()[f\"{target_class}_prediction_mapping\"], idx\n",
    "    )\n",
    "    y_true_all.extend(y_true)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    y_prob_all.extend(y_prob)\n",
    "\n",
    "# Calcula as métricas\n",
    "metrics = calculate_metrics(y_true_all, y_pred_all, y_prob_all, classes)\n",
    "\n",
    "# Caminho para salvar o Excel\n",
    "metrics_output_path = \"prediction_metrics.xlsx\"\n",
    "\n",
    "# Salva as métricas em uma planilha Excel\n",
    "save_metrics_to_excel(metrics, metrics_output_path, classes)\n",
    "\n",
    "print(f\"Métricas salvas na planilha: {metrics_output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
