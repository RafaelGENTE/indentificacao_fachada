{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow xgboost numpy matplotlib scikit-learn opencv-python pillow seaborn pandas setuptools openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vz2u_wL0v9Nr",
    "outputId": "04f3f6af-0603-4ef0-c76d-83abded3a8e2"
   },
   "outputs": [],
   "source": [
    "# some basic libraries\n",
    "import xgboost\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# importing for basic image operations\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# data structures\n",
    "from collections import OrderedDict\n",
    "\n",
    "# importing pretrained models\n",
    "from tensorflow.keras.applications import efficientnet\n",
    "\n",
    "# for splitting data\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# prerequisites for training models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# for selecting better metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# initialize TPU\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)  # Atualização aqui\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(f\"Strategy: {strategy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qHPmaNQS1eCW"
   },
   "outputs": [],
   "source": [
    "# variables to change\n",
    "\n",
    "TRAIN_IMG_DIR_PATH = \"../imagens_bd/results_train\"\n",
    "#TEST_IMG_DIR_PATH = \"../imagens_bd/results_test\" \n",
    "TEST_IMG_DIR_PATH = \"../imagens_bd/results_train\"\n",
    "TRAIN_SC_DIR_PATH = \"../imagens_bd/train-resized\"\n",
    "TEST_SC_DIR_PATH = \"../imagens_bd/test-resized\"\n",
    "model_path = \"../modelo\"\n",
    "#classes = [\"residential\", \"mixed\", \"commercial\",\"others\",\"industrial\"]\n",
    "classes = [\"residential\", \"commercial\",\"others\",\"industrial\"]\n",
    "\n",
    "INPUT_IMG_WIDTH = 250\n",
    "INPUT_IMG_HEIGHT = 350\n",
    "VERTICAL = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando modelos 100 epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_eff_model = tf.keras.models.load_model(model_path + '/' + 'modelo_att(100e).keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Wa37moztmVPz"
   },
   "outputs": [],
   "source": [
    "new_eff_model.load_weights(model_path + '/' + 'modelo_att.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZd52xTW4fk1",
    "outputId": "5d9c5d94-ca9c-468a-a1db-a7a261f563c3"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "target_class = \"residential\"\n",
    "residential_prediction_mapping = OrderedDict()\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "  for file_name in os.listdir(TEST_IMG_DIR_PATH + '/' + target_class):\n",
    "\n",
    "    img = Image.open(TEST_IMG_DIR_PATH + '/' + target_class + '/'+ file_name)\n",
    "    building_image = np.array(ImageOps.fit(img,(250, 350), Image.LANCZOS))\n",
    "    building_image = np.expand_dims(building_image, axis = 0)\n",
    "    residential_prediction_mapping[target_class + '/'+ file_name] = new_eff_model.predict(building_image)\n",
    "\n",
    "target_class = \"commercial\"\n",
    "commercial_prediction_mapping = OrderedDict()\n",
    "with strategy.scope():\n",
    "\n",
    "  for file_name in os.listdir(TEST_IMG_DIR_PATH + '/' + target_class):\n",
    "    img = Image.open(TEST_IMG_DIR_PATH + '/' + target_class + '/'+ file_name)\n",
    "    building_image = np.array(ImageOps.fit(img,(250, 350), Image.LANCZOS))\n",
    "    building_image = np.expand_dims(building_image, axis = 0)\n",
    "    commercial_prediction_mapping[target_class + '/'+ file_name] = new_eff_model.predict(building_image)\n",
    "\n",
    "target_class = \"industrial\"\n",
    "industrial_prediction_mapping = OrderedDict()\n",
    "with strategy.scope():\n",
    "\n",
    "  for file_name in os.listdir(TEST_IMG_DIR_PATH + '/' + target_class):\n",
    "    img = Image.open(TEST_IMG_DIR_PATH + '/' + target_class + '/'+ file_name)\n",
    "    building_image = np.array(ImageOps.fit(img,(250, 350), Image.LANCZOS))\n",
    "    building_image = np.expand_dims(building_image, axis = 0)\n",
    "    industrial_prediction_mapping[target_class + '/'+ file_name] = new_eff_model.predict(building_image)\n",
    "\n",
    "target_class = \"others\"\n",
    "others_prediction_mapping = OrderedDict()\n",
    "with strategy.scope():\n",
    "\n",
    "  for file_name in os.listdir(TEST_IMG_DIR_PATH + '/' + target_class):\n",
    "\n",
    "    img = Image.open(TEST_IMG_DIR_PATH + '/' + target_class + '/'+ file_name)\n",
    "    building_image = np.array(ImageOps.fit(img,(250, 350), Image.LANCZOS))\n",
    "    building_image = np.expand_dims(building_image, axis = 0)\n",
    "    others_prediction_mapping[file_name] = new_eff_model.predict(building_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tnGB8jlN59nt"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "others_predictions = OrderedDict()\n",
    "\n",
    "for file_name in others_prediction_mapping.keys():\n",
    "  # others_predictions[file_name] = np.argmax(others_prediction_mapping[file_name], axis = 1)[0]\n",
    "  others_predictions[file_name] = others_prediction_mapping[file_name]\n",
    "\n",
    "others_scene_predictions = OrderedDict()\n",
    "for file_name in others_predictions.keys():\n",
    "  scene_file_name = '_'.join(os.path.splitext(file_name)[0].split('_')[-3:]) + os.path.splitext(file_name)[1]\n",
    "  if scene_file_name not in others_scene_predictions.keys():\n",
    "    others_scene_predictions[scene_file_name] = [others_predictions[file_name]]\n",
    "  else:\n",
    "    others_scene_predictions[scene_file_name].append(others_predictions[file_name])\n",
    "\n",
    "residential_predictions = OrderedDict()\n",
    "for file_name in residential_prediction_mapping.keys():\n",
    "  # residential_predictions[file_name] = np.argmax(residential_prediction_mapping[file_name], axis = 1)[0]\n",
    "\n",
    "  residential_predictions[file_name] = residential_prediction_mapping[file_name]\n",
    "\n",
    "residential_scene_predictions = OrderedDict()\n",
    "for file_name in residential_predictions.keys():\n",
    "  scene_file_name = '_'.join(os.path.splitext(file_name)[0].split('_')[-3:]) + os.path.splitext(file_name)[1]\n",
    "  if scene_file_name not in residential_scene_predictions.keys():\n",
    "    residential_scene_predictions[scene_file_name] = [residential_predictions[file_name]]\n",
    "  else:\n",
    "    residential_scene_predictions[scene_file_name].append(residential_predictions[file_name])\n",
    "\n",
    "commercial_predictions = OrderedDict()\n",
    "for file_name in commercial_prediction_mapping.keys():\n",
    "  # commercial_predictions[file_name] = np.argmax(commercial_prediction_mapping[file_name], axis = 1)[0]\n",
    "\n",
    "  commercial_predictions[file_name] = commercial_prediction_mapping[file_name]\n",
    "commercial_scene_predictions = OrderedDict()\n",
    "for file_name in commercial_predictions.keys():\n",
    "  scene_file_name = '_'.join(os.path.splitext(file_name)[0].split('_')[-3:]) + os.path.splitext(file_name)[1]\n",
    "  if scene_file_name not in commercial_scene_predictions.keys():\n",
    "    commercial_scene_predictions[scene_file_name] = [commercial_predictions[file_name]]\n",
    "  else:\n",
    "    commercial_scene_predictions[scene_file_name].append(commercial_predictions[file_name])\n",
    "\n",
    "industrial_predictions = OrderedDict()\n",
    "for file_name in industrial_prediction_mapping.keys():\n",
    "  # industrial_predictions[file_name] = np.argmax(industrial_prediction_mapping[file_name], axis = 1)[0]\n",
    "\n",
    "  industrial_predictions[file_name] = industrial_prediction_mapping[file_name]\n",
    "industrial_scene_predictions = OrderedDict()\n",
    "for file_name in industrial_predictions.keys():\n",
    "  scene_file_name = '_'.join(os.path.splitext(file_name)[0].split('_')[-3:]) + os.path.splitext(file_name)[1]\n",
    "  if scene_file_name not in industrial_scene_predictions.keys():\n",
    "    industrial_scene_predictions[scene_file_name] = [industrial_predictions[file_name]]\n",
    "  else:\n",
    "    industrial_scene_predictions[scene_file_name].append(industrial_predictions[file_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbqYZtd8VxeZ"
   },
   "source": [
    " Visualizar Imagens e Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TVofeHZWVv8a",
    "outputId": "eec9e7ab-b1be-4fd4-ad47-a1c9b3646824"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Function to plot a sample of the images and their predictions\n",
    "def plot_sample_images(prediction_mapping, target_class, num_samples=10):\n",
    "    sample_predictions = list(prediction_mapping.items())[:num_samples]\n",
    "    for file_path, prediction in sample_predictions:\n",
    "        # Check if the path does not start with any of the known prefixes\n",
    "        print(file_path)\n",
    "        if not file_path.startswith(('commercial', 'residential', 'industrial')):\n",
    "            file_path = 'others/' + file_path\n",
    "\n",
    "        img = Image.open(TEST_IMG_DIR_PATH + '/' + file_path)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Prediction: {np.argmax(prediction)}\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Plot sample images and their predictions for each class\n",
    "print(\"Residential Images and Predictions:\")\n",
    "plot_sample_images(residential_prediction_mapping, \"residential\")\n",
    "\n",
    "print(\"Commercial Images and Predictions:\")\n",
    "plot_sample_images(commercial_prediction_mapping, \"commercial\")\n",
    "\n",
    "print(\"Industrial Images and Predictions:\")\n",
    "plot_sample_images(industrial_prediction_mapping, \"industrial\")\n",
    "\n",
    "print(\"Other Images and Predictions:\")\n",
    "plot_sample_images(others_prediction_mapping, \"others\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exibir as imagens com as porcentagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Função para calcular as porcentagens das predições e exibir as imagens\n",
    "def plot_sample_images_with_percentages(prediction_mapping, target_class, num_samples=10):\n",
    "    sample_predictions = list(prediction_mapping.items())[:num_samples]\n",
    "\n",
    "    for file_path, prediction in sample_predictions:\n",
    "        # Ajustar o caminho do arquivo para a categoria \"others\", se necessário\n",
    "        if not file_path.startswith(('commercial', 'residential', 'industrial')):\n",
    "            file_path = 'others/' + file_path\n",
    "\n",
    "        # Carregar a imagem\n",
    "        img = Image.open(TEST_IMG_DIR_PATH + '/' + file_path)\n",
    "\n",
    "        # Calcular as porcentagens para cada classe\n",
    "        percentages = {cls: round(prob * 100, 2) for cls, prob in zip(classes, prediction[0])}\n",
    "\n",
    "        # Criar um título com as porcentagens das predições\n",
    "        title = \"\\n\".join([f\"{cls}: {percent}%\" for cls, percent in percentages.items()])\n",
    "\n",
    "        # Exibir a imagem com o título\n",
    "        plt.figure(figsize=(5, 7))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(title, fontsize=10)\n",
    "        plt.show()\n",
    "\n",
    "# Plotando as imagens e suas predições para cada classe\n",
    "print(\"Residential Images and Predictions:\")\n",
    "plot_sample_images_with_percentages(residential_prediction_mapping, \"residential\")\n",
    "\n",
    "print(\"Commercial Images and Predictions:\")\n",
    "plot_sample_images_with_percentages(commercial_prediction_mapping, \"commercial\")\n",
    "\n",
    "print(\"Industrial Images and Predictions:\")\n",
    "plot_sample_images_with_percentages(industrial_prediction_mapping, \"industrial\")\n",
    "\n",
    "print(\"Other Images and Predictions:\")\n",
    "plot_sample_images_with_percentages(others_prediction_mapping, \"others\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Função para calcular as porcentagens das predições e salvar as imagens\n",
    "def save_sample_images_with_percentages(prediction_mapping, target_class, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Garante que o diretório de saída exista\n",
    "\n",
    "    for file_path, prediction in prediction_mapping.items():\n",
    "        # Ajustar o caminho do arquivo para a categoria \"others\", se necessário\n",
    "        if not file_path.startswith(('commercial', 'residential', 'industrial')):\n",
    "            file_path = 'others/' + file_path\n",
    "\n",
    "        # Carregar a imagem\n",
    "        img = Image.open(TEST_IMG_DIR_PATH + '/' + file_path)\n",
    "\n",
    "        # Calcular as porcentagens para cada classe\n",
    "        percentages = {cls: round(prob * 100, 2) for cls, prob in zip(classes, prediction[0])}\n",
    "\n",
    "        # Criar um título com as porcentagens das predições\n",
    "        title = \"\\n\".join([f\"{cls}: {percent}%\" for cls, percent in percentages.items()])\n",
    "\n",
    "        # Exibir a imagem com o título e salvar como arquivo JPEG\n",
    "        plt.figure(figsize=(5, 7))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(title, fontsize=10)\n",
    "\n",
    "        # Salvar a imagem na pasta de saída\n",
    "        output_path = os.path.join(output_dir, file_path.replace(\"/\", \"_\").replace(\"\\\\\", \"_\") + \".jpeg\")\n",
    "        plt.savefig(output_path, format='jpeg', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# Diretório de saída\n",
    "output_base_dir = \"output_images_2\"\n",
    "\n",
    "# Salvando as imagens para cada classe\n",
    "save_sample_images_with_percentages(residential_prediction_mapping, \"residential\", os.path.join(output_base_dir, \"residential\"))\n",
    "save_sample_images_with_percentages(commercial_prediction_mapping, \"commercial\", os.path.join(output_base_dir, \"commercial\"))\n",
    "save_sample_images_with_percentages(industrial_prediction_mapping, \"industrial\", os.path.join(output_base_dir, \"industrial\"))\n",
    "save_sample_images_with_percentages(others_prediction_mapping, \"others\", os.path.join(output_base_dir, \"others\"))\n",
    "\n",
    "print(f\"Imagens salvas na pasta '{output_base_dir}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportar as tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_predictions_with_percentages(image_dir, target_class, model, classes):\n",
    "    prediction_mapping = OrderedDict()\n",
    "\n",
    "    for file_name in os.listdir(image_dir + '/' + target_class):\n",
    "        img = Image.open(image_dir + '/' + target_class + '/' + file_name)\n",
    "        building_image = np.array(ImageOps.fit(img, (INPUT_IMG_WIDTH, INPUT_IMG_HEIGHT), Image.LANCZOS))\n",
    "        building_image = np.expand_dims(building_image, axis=0)\n",
    "        prediction = model.predict(building_image)[0]  # Obter o vetor de probabilidades\n",
    "        percentages = {cls: f\"{round(prob * 100, 2)}%\" for cls, prob in zip(classes, prediction)}\n",
    "        prediction_mapping[file_name] = percentages\n",
    "\n",
    "    return prediction_mapping\n",
    "\n",
    "# Gera predições para todas as classes\n",
    "all_predictions = {}\n",
    "for target_class in classes:\n",
    "    predictions = get_predictions_with_percentages(TEST_IMG_DIR_PATH, target_class, new_eff_model, classes)\n",
    "    all_predictions[target_class] = predictions\n",
    "\n",
    "# Criar uma tabela visual\n",
    "def create_prediction_table(predictions_dict):\n",
    "    all_data = []\n",
    "    for target_class, predictions in predictions_dict.items():\n",
    "        for file_name, percentages in predictions.items():\n",
    "            row = {\"Image\": file_name, \"True Class\": target_class, **percentages}\n",
    "            all_data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "# Cria tabela consolidada\n",
    "prediction_table = create_prediction_table(all_predictions)\n",
    "\n",
    "# Salva a tabela em um arquivo Excel\n",
    "output_path = \"prediction_percentages_table.xlsx\"\n",
    "prediction_table.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"A tabela foi salva em: {output_path}\")\n",
    "\n",
    "# Exibe a tabela diretamente no console\n",
    "print(prediction_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportar as tabelas com as imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions with images saved to: predictions_with_images.xlsx\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "from openpyxl.drawing.image import Image as OpenPyxlImage\n",
    "import os\n",
    "\n",
    "def save_predictions_with_images_to_excel(predictions_dict, image_dir, output_path, classes):\n",
    "    # Cria uma pasta temporária para salvar as imagens\n",
    "    temp_image_dir = \"temp_images\"\n",
    "    os.makedirs(temp_image_dir, exist_ok=True)\n",
    "\n",
    "    # Cria uma nova planilha Excel\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Predictions\"\n",
    "\n",
    "    # Cabeçalhos\n",
    "    headers = [\"Image\", \"True Class\", \"Image Path\"] + classes\n",
    "    ws.append(headers)\n",
    "\n",
    "    # Adiciona as predições e imagens à planilha\n",
    "    row_index = 2\n",
    "    for target_class, predictions in predictions_dict.items():\n",
    "        for file_name, percentages in predictions.items():\n",
    "            # Salvar a imagem temporariamente\n",
    "            img_path = os.path.join(image_dir, target_class, file_name)\n",
    "            temp_img_path = os.path.join(temp_image_dir, file_name)\n",
    "            img = Image.open(img_path)\n",
    "            img.save(temp_img_path)\n",
    "\n",
    "            # Adiciona as informações à planilha\n",
    "            row = [file_name, target_class, temp_img_path] + [percentages[cls] for cls in classes]\n",
    "            ws.append(row)\n",
    "\n",
    "            # Insere a imagem na célula correspondente\n",
    "            img_openpyxl = OpenPyxlImage(temp_img_path)\n",
    "            ws.add_image(img_openpyxl, f\"C{row_index}\")\n",
    "\n",
    "            row_index += 1\n",
    "\n",
    "    # Salva a planilha\n",
    "    wb.save(output_path)\n",
    "\n",
    "    # Remove as imagens temporárias\n",
    "    for temp_file in os.listdir(temp_image_dir):\n",
    "        os.remove(os.path.join(temp_image_dir, temp_file))\n",
    "    os.rmdir(temp_image_dir)\n",
    "\n",
    "    print(f\"Predictions with images saved to: {output_path}\")\n",
    "\n",
    "# Gera a tabela com as predições e imagens\n",
    "output_excel_path = \"predictions_with_images.xlsx\"\n",
    "save_predictions_with_images_to_excel(all_predictions, TEST_IMG_DIR_PATH, output_excel_path, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# Função para calcular métricas\n",
    "def calculate_metrics(y_true, y_pred, y_prob, class_names):\n",
    "    metrics = {}\n",
    "\n",
    "    # Acurácia\n",
    "    metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Precisão, Recall, F1-Score\n",
    "    metrics['precision'] = precision_score(y_true, y_pred, average='weighted')\n",
    "    metrics['recall'] = recall_score(y_true, y_pred, average='weighted')\n",
    "    metrics['f1_score'] = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    # Matriz de Confusão\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    metrics['confusion_matrix'] = cm\n",
    "\n",
    "    # Relatório de Classificação\n",
    "    metrics['classification_report'] = classification_report(y_true, y_pred, target_names=class_names)\n",
    "\n",
    "    # AUC-ROC (se y_prob estiver disponível)\n",
    "    if y_prob is not None:\n",
    "        metrics['roc_auc'] = roc_auc_score(y_true, y_prob, multi_class='ovr', average='weighted')\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Preparando os dados para cálculo\n",
    "def prepare_data_for_metrics(prediction_mapping, target_class_index):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_prob = []\n",
    "\n",
    "    for file_name, predictions in prediction_mapping.items():\n",
    "        y_true.append(target_class_index)  # Classe verdadeira\n",
    "        y_pred.append(np.argmax(predictions))  # Classe predita\n",
    "        y_prob.append(predictions[0])  # Vetor de probabilidades\n",
    "\n",
    "    return y_true, y_pred, y_prob\n",
    "\n",
    "# Consolida os dados de todas as classes\n",
    "y_true_all, y_pred_all, y_prob_all = [], [], []\n",
    "\n",
    "for idx, target_class in enumerate(classes):\n",
    "    y_true, y_pred, y_prob = prepare_data_for_metrics(\n",
    "        locals()[f\"{target_class}_prediction_mapping\"], idx\n",
    "    )\n",
    "    y_true_all.extend(y_true)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    y_prob_all.extend(y_prob)\n",
    "\n",
    "# Calcula as métricas\n",
    "metrics = calculate_metrics(y_true_all, y_pred_all, y_prob_all, classes)\n",
    "\n",
    "# Exibindo as métricas\n",
    "print(\"Acurácia:\", metrics['accuracy'])\n",
    "print(\"\\nPrecisão:\", metrics['precision'])\n",
    "print(\"\\nRecall:\", metrics['recall'])\n",
    "print(\"\\nF1-Score:\", metrics['f1_score'])\n",
    "print(\"\\nMatriz de Confusão:\\n\", metrics['confusion_matrix'])\n",
    "print(\"\\nRelatório de Classificação:\\n\", metrics['classification_report'])\n",
    "\n",
    "if 'roc_auc' in metrics:\n",
    "    print(\"\\nAUC-ROC:\", metrics['roc_auc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configurar o diretório de logs para o TensorBoard\n",
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "# Função para logar métricas no TensorBoard\n",
    "def log_metrics_to_tensorboard(metrics, y_true, y_pred, class_names, step=0):\n",
    "    with summary_writer.as_default():\n",
    "        # Logar métricas gerais\n",
    "        tf.summary.scalar(\"Accuracy\", metrics['accuracy'], step=step)\n",
    "        tf.summary.scalar(\"Precision\", metrics['precision'], step=step)\n",
    "        tf.summary.scalar(\"Recall\", metrics['recall'], step=step)\n",
    "        tf.summary.scalar(\"F1 Score\", metrics['f1_score'], step=step)\n",
    "        \n",
    "        if 'roc_auc' in metrics:\n",
    "            tf.summary.scalar(\"AUC-ROC\", metrics['roc_auc'], step=step)\n",
    "        \n",
    "        # Matriz de Confusão como imagem\n",
    "        cm = metrics['confusion_matrix']\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        \n",
    "        # Salvar a matriz de confusão como imagem no TensorBoard\n",
    "        plt.savefig(\"confusion_matrix.png\")\n",
    "        plt.close()\n",
    "        cm_image = tf.io.read_file(\"confusion_matrix.png\")\n",
    "        cm_image = tf.image.decode_png(cm_image)\n",
    "        tf.summary.image(\"Confusion Matrix\", tf.expand_dims(cm_image, axis=0), step=step)\n",
    "\n",
    "# Preparando os dados para cálculo\n",
    "def prepare_data_for_metrics(prediction_mapping, target_class_index):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_prob = []\n",
    "\n",
    "    for file_name, predictions in prediction_mapping.items():\n",
    "        y_true.append(target_class_index)  # Classe verdadeira\n",
    "        y_pred.append(np.argmax(predictions))  # Classe predita\n",
    "        y_prob.append(predictions[0])  # Vetor de probabilidades\n",
    "\n",
    "    return y_true, y_pred, y_prob\n",
    "\n",
    "# Consolida os dados de todas as classes\n",
    "y_true_all, y_pred_all, y_prob_all = [], [], []\n",
    "\n",
    "for idx, target_class in enumerate(classes):\n",
    "    y_true, y_pred, y_prob = prepare_data_for_metrics(\n",
    "        locals()[f\"{target_class}_prediction_mapping\"], idx\n",
    "    )\n",
    "    y_true_all.extend(y_true)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    y_prob_all.extend(y_prob)\n",
    "\n",
    "# Calcula as métricas\n",
    "metrics = calculate_metrics(y_true_all, y_pred_all, y_prob_all, classes)\n",
    "\n",
    "# Exibindo as métricas no console\n",
    "print(\"Acurácia:\", metrics['accuracy'])\n",
    "print(\"\\nPrecisão:\", metrics['precision'])\n",
    "print(\"\\nRecall:\", metrics['recall'])\n",
    "print(\"\\nF1-Score:\", metrics['f1_score'])\n",
    "print(\"\\nMatriz de Confusão:\\n\", metrics['confusion_matrix'])\n",
    "print(\"\\nRelatório de Classificação:\\n\", metrics['classification_report'])\n",
    "\n",
    "if 'roc_auc' in metrics:\n",
    "    print(\"\\nAUC-ROC:\", metrics['roc_auc'])\n",
    "\n",
    "# Logar métricas no TensorBoard\n",
    "log_metrics_to_tensorboard(metrics, y_true_all, y_pred_all, classes)\n",
    "\n",
    "# Iniciar o TensorBoard (apenas no notebook, opcional)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score\n",
    ")\n",
    "\n",
    "# Funções auxiliares\n",
    "def calculate_metrics(y_true, y_pred, y_prob, class_names):\n",
    "    metrics = {}\n",
    "\n",
    "    # Acurácia\n",
    "    metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Precisão, Recall, F1-Score\n",
    "    metrics['precision'] = precision_score(y_true, y_pred, average='weighted')\n",
    "    metrics['recall'] = recall_score(y_true, y_pred, average='weighted')\n",
    "    metrics['f1_score'] = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    # Matriz de Confusão\n",
    "    metrics['confusion_matrix'] = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Relatório de Classificação\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "    metrics['classification_report'] = report\n",
    "\n",
    "    # AUC-ROC (se y_prob estiver disponível)\n",
    "    if y_prob is not None:\n",
    "        metrics['roc_auc'] = roc_auc_score(y_true, y_prob, multi_class='ovr', average='weighted')\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def prepare_data_for_metrics(prediction_mapping, target_class_index):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_prob = []\n",
    "\n",
    "    for file_name, predictions in prediction_mapping.items():\n",
    "        y_true.append(target_class_index)  # Classe verdadeira\n",
    "        y_pred.append(np.argmax(predictions))  # Classe predita\n",
    "        y_prob.append(predictions[0])  # Vetor de probabilidades\n",
    "\n",
    "    return y_true, y_pred, y_prob\n",
    "\n",
    "def save_metrics_to_excel(metrics, output_path, class_names):\n",
    "    with pd.ExcelWriter(output_path) as writer:\n",
    "        # Salva métricas gerais\n",
    "        general_metrics = {\n",
    "            \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"AUC-ROC\"],\n",
    "            \"Value\": [\n",
    "                metrics.get('accuracy', 'N/A'),\n",
    "                metrics.get('precision', 'N/A'),\n",
    "                metrics.get('recall', 'N/A'),\n",
    "                metrics.get('f1_score', 'N/A'),\n",
    "                metrics.get('roc_auc', 'N/A'),\n",
    "            ]\n",
    "        }\n",
    "        pd.DataFrame(general_metrics).to_excel(writer, sheet_name=\"General Metrics\", index=False)\n",
    "\n",
    "        # Salva matriz de confusão\n",
    "        cm_df = pd.DataFrame(metrics['confusion_matrix'], index=class_names, columns=class_names)\n",
    "        cm_df.to_excel(writer, sheet_name=\"Confusion Matrix\")\n",
    "\n",
    "        # Salva relatório de classificação\n",
    "        report_dict = metrics['classification_report']\n",
    "        report_df = pd.DataFrame(report_dict).transpose()\n",
    "        report_df.to_excel(writer, sheet_name=\"Classification Report\", index=True)\n",
    "\n",
    "# Variáveis do modelo e predições (preencher com seus dados)\n",
    "classes = [\"residential\", \"commercial\", \"others\", \"industrial\"]\n",
    "\n",
    "# Exemplo para carregar predições (substitua pelos seus dados reais)\n",
    "# y_true_all, y_pred_all, y_prob_all devem ser gerados a partir das predições\n",
    "y_true_all, y_pred_all, y_prob_all = [], [], []\n",
    "\n",
    "for idx, target_class in enumerate(classes):\n",
    "    y_true, y_pred, y_prob = prepare_data_for_metrics(\n",
    "        locals()[f\"{target_class}_prediction_mapping\"], idx\n",
    "    )\n",
    "    y_true_all.extend(y_true)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    y_prob_all.extend(y_prob)\n",
    "\n",
    "# Calcula as métricas\n",
    "metrics = calculate_metrics(y_true_all, y_pred_all, y_prob_all, classes)\n",
    "\n",
    "# Caminho para salvar o Excel\n",
    "metrics_output_path = \"prediction_metrics.xlsx\"\n",
    "\n",
    "# Salva as métricas em uma planilha Excel\n",
    "save_metrics_to_excel(metrics, metrics_output_path, classes)\n",
    "\n",
    "print(f\"Métricas salvas na planilha: {metrics_output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
